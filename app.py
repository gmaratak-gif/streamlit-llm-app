from dotenv import load_dotenv

load_dotenv()

import os
from typing import Literal

import streamlit as st
from dotenv import load_dotenv

# === 1) ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«: .env / æœ¬ç•ª: Secretsï¼‰ ===
# ãƒ­ãƒ¼ã‚«ãƒ«ï¼ˆ.envï¼‰ã‚’å…ˆã«èª­ã¿è¾¼ã‚€
load_dotenv()

# Streamlit Cloud å´ï¼ˆSecretsï¼‰ã«ã‚ã‚Œã°ä¸Šæ›¸ãåˆ©ç”¨
if "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")

# === 2) LangChain / OpenAI ã®æº–å‚™ ===
#   â€» Lesson8 ã‚¹ã‚¿ã‚¤ãƒ«ï¼šChatOpenAI + ChatPromptTemplate + StrOutputParser
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# é¸æŠã§ãã‚‹å°‚é–€å®¶ãƒ­ãƒ¼ãƒ«ï¼ˆA/Bï¼‰
ExpertKey = Literal["æ ªå¼æŠ•è³‡ã‚¢ãƒŠãƒªã‚¹ãƒˆï¼ˆAï¼‰", "ç”ŸæˆAIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ï¼ˆBï¼‰"]

EXPERT_SYSTEM_MESSAGES: dict[ExpertKey, str] = {
    "æ ªå¼æŠ•è³‡ã‚¢ãƒŠãƒªã‚¹ãƒˆï¼ˆAï¼‰": (
        "ã‚ãªãŸã¯å³æ ¼ã§å®¢è¦³çš„ãªæ ªå¼æŠ•è³‡ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚"
        "å¸¸ã«æ ¹æ‹ ãƒ»å‰æãƒ»ãƒªã‚¹ã‚¯ãƒ»ä»£æ›¿æ¡ˆã‚’æç¤ºã—ã€"
        "å°‚é–€ç”¨èªã¯çŸ­ãèª¬æ˜ã‚’æ·»ãˆã¦ãã ã•ã„ã€‚"
        "æ¨å¥¨ã¯æ–­å®šã›ãšã€æŠ•è³‡åŠ©è¨€ã§ã¯ãªãæ•™è‚²ç›®çš„ã®è¦‹è§£ã¨ã—ã¦è¿°ã¹ã¾ã™ã€‚"
    ),
    "ç”ŸæˆAIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ï¼ˆBï¼‰": (
        "ã‚ãªãŸã¯å®Ÿå‹™ã«å¼·ã„ç”ŸæˆAIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚"
        "è¨­è¨ˆæ–¹é‡â†’æ‰‹é †â†’ã‚³ãƒ¼ãƒ‰ä¾‹â†’æ¤œè¨¼æ–¹æ³•â†’é‹ç”¨ä¸Šã®æ³¨æ„ã®é †ã§ã€"
        "å…·ä½“çš„ã‹ã¤å†ç¾å¯èƒ½ãªæ‰‹é †ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
        "å‰ææ¡ä»¶ã‚„åˆ¶ç´„ãŒã‚ã‚Œã°æœ€åˆã«æ˜ç¤ºã—ã¾ã™ã€‚"
    ),
}

def build_chain(expert_key: ExpertKey, model_name: str = "gpt-4o-mini", temperature: float = 0.2):
    """é¸æŠã—ãŸå°‚é–€å®¶ãƒ­ãƒ¼ãƒ«ã§ LangChain ã®ãƒã‚§ãƒ¼ãƒ³ã‚’æ§‹ç¯‰ã—ã¦è¿”ã™ã€‚"""
    system_msg = EXPERT_SYSTEM_MESSAGES[expert_key]

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_msg),
            ("human", "{user_input}"),
        ]
    )

    llm = ChatOpenAI(
        model=model_name,
        temperature=temperature,
        # APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã‚’ä½¿ç”¨ï¼ˆä¸Šã§è¨­å®šæ¸ˆã¿ï¼‰
    )

    parser = StrOutputParser()
    chain = prompt | llm | parser
    return chain

def get_llm_answer(user_text: str, expert_key: ExpertKey, model_name: str = "gpt-4o-mini", temperature: float = 0.2) -> str:
    """
    æ¡ä»¶ï¼š
      - å¼•æ•°: ã€Œå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã€ã€Œãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§ã®é¸æŠå€¤ã€
      - æˆ»ã‚Šå€¤: LLMã‹ã‚‰ã®å›ç­”ï¼ˆæ–‡å­—åˆ—ï¼‰
    """
    chain = build_chain(expert_key=expert_key, model_name=model_name, temperature=temperature)
    return chain.invoke({"user_input": user_text})


# === 3) Streamlit UI ===
st.set_page_config(page_title="Streamlit Ã— LangChain LLM ã‚¢ãƒ—ãƒª", page_icon="ğŸ¤–", layout="centered")

st.title("ğŸ¤– Streamlit Ã— LangChain LLM ã‚¢ãƒ—ãƒª")
st.caption("Python 3.11 / LangChain / OpenAI APIï¼ˆ.env ã¾ãŸã¯ Streamlit Secretsï¼‰")

with st.expander("â„¹ï¸ ã‚¢ãƒ—ãƒªã®æ¦‚è¦ãƒ»ä½¿ã„æ–¹", expanded=True):
    st.markdown(
        
    )

# APIã‚­ãƒ¼æœªè¨­å®šã®æ—©æœŸè­¦å‘Šï¼ˆå®Ÿè¡Œã¯å¯èƒ½ã ãŒé€ä¿¡æ™‚ã«å†ãƒã‚§ãƒƒã‚¯ï¼‰
if not OPENAI_API_KEY:
    st.warning("OPENAI_API_KEY ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚.env ã¾ãŸã¯ Streamlit Secrets ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚", icon="âš ï¸")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®šï¼‰
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    model_name = st.selectbox("ãƒ¢ãƒ‡ãƒ«", ["gpt-4o-mini", "gpt-4o", "gpt-4.1-mini"], index=0)
    temperature = st.slider("Temperatureï¼ˆå‰µé€ æ€§ï¼‰", 0.0, 1.0, 0.2, 0.1)
    st.markdown("---")
    st.markdown("**ãƒ‡ãƒ—ãƒ­ã‚¤æ³¨æ„**: Streamlit Cloud ã§ã¯ Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ 3.11 ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")

# å°‚é–€å®¶ãƒ­ãƒ¼ãƒ«é¸æŠï¼ˆãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ï¼šA / Bï¼‰
expert_choice: ExpertKey = st.radio(
    "å°‚é–€å®¶ãƒ­ãƒ¼ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š",
    options=list(EXPERT_SYSTEM_MESSAGES.keys()),
    horizontal=True,
)

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
with st.form(key="llm_form", clear_on_submit=False):
    user_text = st.text_area(
        "è³ªå• / ãŠé¡Œ",
        placeholder="ä¾‹ï¼‰ã“ã®ãƒ†ãƒ¼ãƒã§æŠ•è³‡ã®ãƒªã‚¹ã‚¯è¦å› ã‚’æ•´ç†ã—ã¦ã€å„ªå…ˆé †ä½ã‚’ã¤ã‘ã¦ãã ã•ã„â€¦",
        height=140,
    )
    submitted = st.form_submit_button("é€ä¿¡")

# é€ä¿¡å‡¦ç†
if submitted:
    if not OPENAI_API_KEY:
        st.error("OPENAI_API_KEY ãŒæœªè¨­å®šã§ã™ã€‚.env ã‚‚ã—ãã¯ Streamlit Secrets ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    elif not user_text.strip():
        st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("LLM ãŒè€ƒãˆã¦ã„ã¾ã™â€¦"):
            try:
                answer = get_llm_answer(
                    user_text=user_text.strip(),
                    expert_key=expert_choice,
                    model_name=model_name,
                    temperature=temperature,
                )
                st.success("å›ç­”ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
                st.markdown("### ğŸ“ å›ç­”")
                st.markdown(answer)
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# ãƒ•ãƒƒã‚¿ãƒ¼ï¼ˆã‚¬ã‚¤ãƒ‰ï¼‰
st.markdown(

)
